{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rating based Prediction Model using ML techniques and NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP8M7KyVGaTdSNUnrmQqaFg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/worklifesg/Natural-Language-Processing/blob/main/Projects/3.%20Rating-Reviews%20based%20Prediction%20Model/Rating_based_Prediction_Model_using_ML_techniques_and_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aFsK1526Q4f"
      },
      "source": [
        "<h3 align='center'>Rating based Prediction Model using ML techniques and NLP </h3> \n",
        "\n",
        "In this program, rating prediction model using NLP and machine learning techniques such as Random Forest, AdaBoost and Naives Bayes are implemented. \n",
        "\n",
        "<b> The final objective of this program is to perform and evaluate best estimator and identigy the mismatch cases. </b>\n",
        "\n",
        "<b> DESCRIPTION </b>\n",
        "\n",
        "Using NLP and machine learning, make a model to predict the rating in a review based on the content of the text review. This will help identify cases with a mismatch.\n",
        "\n",
        "<b> Problem Statement: </b>  \n",
        "\n",
        "Zomato is Indiaâ€™s largest platform for discovering restaurants and ordering food. It operates in India as well as a few cities internationally. Bangalore is one of the biggest customers and restaurant bases for Zomato with 4 to 5 million users using the platform each month.\n",
        "\n",
        "Users on the platform can also post reviews of restaurants and provide a rating accompanying the review. The content in the reviews should ideally reflect the rating provided by the customer. In many cases, there is a mismatch, owing to multiple reasons, where the rating does not match the customer review. The reviews and rating match is very important as it builds customer trust on the platform and helps the user get an accurate picture of the restaurant. \n",
        "\n",
        "You, as a data scientist, need to enable the identification and cleanup of such cases to ensure the ratings reflect the reviews and that the reviews seem trustworthy to the customer. You will need to use NLP techniques in conjunction with machine learning models to predict the rating from the review text.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRkSiuo47E4c"
      },
      "source": [
        "#### Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bNfnkk_7Elc"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from string import punctuation\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XK7HVjT8Nej"
      },
      "source": [
        "#### 1. Load the data using read_csv function from pandas package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "J47PB5pM8SYS",
        "outputId": "9f1b38cb-dfce-45fc-ff71-b028d79e28ee"
      },
      "source": [
        "#Read the dataset\n",
        "df = pd.read_csv('Zomato_reviews.csv')\n",
        "df.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>Their service is worst, pricing in menu is dif...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>really appreciate their quality and timing . I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Went there on a Friday night, the place was su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0</td>\n",
              "      <td>A very decent place serving good food.\\r\\nOrde...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>One of the BEST places for steaks in the city....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   rating                                        review_text\n",
              "0     1.0  Their service is worst, pricing in menu is dif...\n",
              "1     5.0  really appreciate their quality and timing . I...\n",
              "2     4.0  Went there on a Friday night, the place was su...\n",
              "3     4.0  A very decent place serving good food.\\r\\nOrde...\n",
              "4     5.0  One of the BEST places for steaks in the city...."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFrtJIhs7-iy"
      },
      "source": [
        "#### 2. Remove the records where the review text is null"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDzFiLJQ_eNx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96644fd6-7ec6-469c-a39c-bb01f9cd9956"
      },
      "source": [
        "#checking the dataset size\n",
        "\n",
        "print('Zomato reviews dataset has %.f rows and %.f columns'%(df.shape[0],df.shape[1]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zomato reviews dataset has 27762 rows and 2 columns\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlXfoeSr88Js",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "0a103432-c798-4334-d21a-7f92dc8bf740"
      },
      "source": [
        "#Checking missing data\n",
        "null_sum = df.isnull().sum() #sum wise\n",
        "null_count = df.isnull().count() #count wise\n",
        "null_percent = null_sum/null_count*100\n",
        "\n",
        "print(null_sum)\n",
        "pd.concat([null_sum, null_percent],axis=1,keys=['Total','Percent']).transpose()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rating          0\n",
            "review_text    14\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Total</th>\n",
              "      <td>0.0</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Percent</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.050429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         rating  review_text\n",
              "Total       0.0    14.000000\n",
              "Percent     0.0     0.050429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCbEXXKZ9Frr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "b3b6417a-0761-4d32-a832-d56a502994f6"
      },
      "source": [
        "##Removing rows that has null values\n",
        "df_1 = df.dropna()\n",
        "print('Zomato reviews dataset has %.f rows and %.f columns'%(df_1.shape[0],df_1.shape[1]))\n",
        "\n",
        "#Checking missing data\n",
        "null_sum1 = df_1.isnull().sum() #sum wise\n",
        "null_count1 = df_1.isnull().count() #count wise\n",
        "null_percent1 = null_sum1/null_count1*100\n",
        "\n",
        "print(null_sum1)\n",
        "pd.concat([null_sum1, null_percent1],axis=1,keys=['Total','Percent']).transpose()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zomato reviews dataset has 27748 rows and 2 columns\n",
            "rating         0\n",
            "review_text    0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rating</th>\n",
              "      <th>review_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Total</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Percent</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         rating  review_text\n",
              "Total       0.0          0.0\n",
              "Percent     0.0          0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTXEQTWy-0Mz"
      },
      "source": [
        "#### 3. Perform cleanup on the data \n",
        "  - Normalize the casing\n",
        "  - Remove extra line breaks from the text\n",
        "  - Remove stop words. Note: Terms like â€˜noâ€™, â€˜notâ€™, â€˜donâ€™, â€˜wonâ€™ are important, donâ€™t remove\n",
        "  - Remove punctuation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCtXWImO9qyD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be8c7437-b742-417d-f4e4-5393db132c13"
      },
      "source": [
        "import nltk;\n",
        "nltk.download('punkt');\n",
        "nltk.download('stopwords');\n",
        "nltk.download('wordnet', quiet=True)\n",
        "\n",
        "#Normalizing to lower case\n",
        "lower_text = [txt.lower() for txt in df_1['review_text']]\n",
        "print('The text after applying lower case looks like: \\n',lower_text[3:5])\n",
        "print('-------------------------------------------------------------------------------------------')\n",
        "\n",
        "#Remove extra line breaks\n",
        "linebreak_text = [' '.join(txt.split()) for txt in lower_text]\n",
        "print('The text after removing line breaks to lower case text looks like: \\n', linebreak_text[3:5])\n",
        "print('-------------------------------------------------------------------------------------------')\n",
        "\n",
        "#Applying tokenization to lower case text after line breaks\n",
        "\n",
        "token = word_tokenize(linebreak_text[0])\n",
        "print('Tokens for a sample are: \\n', token)\n",
        "print('-------------------------------------------------------------------------------------------')\n",
        "tokens_total = [word_tokenize(wd) for wd in linebreak_text]\n",
        "print('The tokenized sentence looks like: \\n',linebreak_text[0])\n",
        "print('-------------------------------------------------------------------------------------------')\n",
        "\n",
        "#Remove stopwords and punctuation\n",
        "\n",
        "stop_words = stopwords.words('english')\n",
        "stop_punct = list(punctuation)\n",
        "\n",
        "print('Stop words are : \\n',stop_words)\n",
        "print('-------------------------------------------------------------------------------------------')\n",
        "\n",
        "stop_words.remove('no')\n",
        "stop_words.remove('not')\n",
        "stop_words.remove('don')\n",
        "stop_words.remove('won')\n",
        "\n",
        "print('Is word no in the stop words list : ','no' in stop_words)\n",
        "print('-------------------------------------------------------------------------------------------')\n",
        "\n",
        "stop_final = stop_words + stop_punct + ['...','``',\"''\",'====','must']\n",
        "\n",
        "#creating a function for data cleaning\n",
        "def delete(wd):\n",
        "  return [term for term in wd if term not in stop_final]\n",
        "\n",
        "print('Review after removing stop_final \\n ',delete(tokens_total[1]))\n",
        "print('-------------------------------------------------------------------------------------------')\n",
        "\n",
        "token_clean = [delete(wd) for wd in tokens_total]\n",
        "\n",
        "df_clean = [' '.join(wd) for wd in token_clean]\n",
        "\n",
        "print('Final cleaned data (first two reviews): \\n',df_clean[:2])\n",
        "print('-------------------------------------------------------------------------------------------')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "The text after applying lower case looks like: \n",
            " ['a very decent place serving good food.\\r\\nordered chilli fish, chicken & pork sizzler.\\r\\neverything tasted good but pork could have been slightly better cooked.\\r\\ntried 2 beverages, both were very sweet.', 'one of the best places for steaks in the city. tried the beef steak with chili rum & grilled fish with orange and jalapenos. both were exceptionally good. the herbed rice and mashed potatoes serves alongside were equally delecatble. service is prompt and zomato gold is a great steal. if you are a steak lover, this place is a must visit. hope they come up with another ourself somewhere in the cbd.\\r\\n\\r\\nwish to be back soon.\\r\\nbon appetit !']\n",
            "-------------------------------------------------------------------------------------------\n",
            "The text after removing line breaks to lower case text looks like: \n",
            " ['a very decent place serving good food. ordered chilli fish, chicken & pork sizzler. everything tasted good but pork could have been slightly better cooked. tried 2 beverages, both were very sweet.', 'one of the best places for steaks in the city. tried the beef steak with chili rum & grilled fish with orange and jalapenos. both were exceptionally good. the herbed rice and mashed potatoes serves alongside were equally delecatble. service is prompt and zomato gold is a great steal. if you are a steak lover, this place is a must visit. hope they come up with another ourself somewhere in the cbd. wish to be back soon. bon appetit !']\n",
            "-------------------------------------------------------------------------------------------\n",
            "Tokens for a sample are: \n",
            " ['their', 'service', 'is', 'worst', ',', 'pricing', 'in', 'menu', 'is', 'different', 'from', 'bill', '.', 'they', 'can', 'give', 'you', 'a', 'bill', 'with', 'increased', 'pricing', '.', 'even', 'for', 'serving', 'water', ',', 'menu', ',', 'order', 'you', 'need', 'to', 'call', 'them', '3-4', 'times', 'even', 'on', 'a', 'non', 'busy', 'day', '.']\n",
            "-------------------------------------------------------------------------------------------\n",
            "The tokenized sentence looks like: \n",
            " their service is worst, pricing in menu is different from bill. they can give you a bill with increased pricing. even for serving water,menu, order you need to call them 3-4 times even on a non busy day.\n",
            "-------------------------------------------------------------------------------------------\n",
            "Stop words are : \n",
            " ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "-------------------------------------------------------------------------------------------\n",
            "Is word no in the stop words list :  False\n",
            "-------------------------------------------------------------------------------------------\n",
            "Review after removing stop_final \n",
            "  ['really', 'appreciate', 'quality', 'timing', 'tried', 'thattil', 'kutti', 'dosa', \"'ve\", 'addicted', 'dosa', 'really', 'chutney', 'really', 'good', 'money', 'worth', 'much', 'better', 'thattukada', 'try']\n",
            "-------------------------------------------------------------------------------------------\n",
            "Final cleaned data (first two reviews): \n",
            " ['service worst pricing menu different bill give bill increased pricing even serving water menu order need call 3-4 times even non busy day', \"really appreciate quality timing tried thattil kutti dosa 've addicted dosa really chutney really good money worth much better thattukada try\"]\n",
            "-------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91J504OsGDKz"
      },
      "source": [
        "#### 4. Separation into train and test sets\n",
        "\n",
        "  - Use train-test method to divide your data into 2 sets: train and test\n",
        "  - Use a 70-30 split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDSEM3YZIJL0"
      },
      "source": [
        "X_train, X_test,y_train,y_test = train_test_split(df_clean,df_1['rating'],test_size=0.3,random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXBMGNb4GP38"
      },
      "source": [
        "#### 5. Use TF-IDF values for the terms as features to get into a vector space model\n",
        "\n",
        " - Import TF-IDF vectorizer from sklearn\n",
        " - Instantiate with a maximum of 5000 terms in your vocabulary\n",
        " - Fit and apply on the train set\n",
        " - Apply on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MerHRNYmJyIK",
        "outputId": "37ffdbcc-fd8b-4f89-83ca-d1d14e4d2c85"
      },
      "source": [
        "#creating tfidf and vectorizing training and testing dataset\n",
        "vector = TfidfVectorizer(max_features=5000)\n",
        "\n",
        "#fit and apply to training and testing dataset\n",
        "X_train_tfidf = vector.fit_transform(X_train)\n",
        "X_test_tfidf = vector.fit_transform(X_test)\n",
        "\n",
        "print('Training size : ',X_train_tfidf.shape)\n",
        "print('Testing size : ', X_test_tfidf.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size :  (19423, 5000)\n",
            "Testing size :  (8325, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oi2t79M8GPnD"
      },
      "source": [
        "#### 6. Model building: Random Forest Regressor\n",
        "\n",
        " - Instantiate RandomForestRegressor from sklearn (set random seed)\n",
        " - Fit on the train data\n",
        " - Make predictions for the train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-gt67vbLO8R",
        "outputId": "32c1fa78-f03b-4f1d-d410-84d9dd920431"
      },
      "source": [
        "# RandomForestRegressor model built\n",
        "model_RF = RandomForestRegressor(n_estimators=10, random_state=42)\n",
        "\n",
        "#Training the model\n",
        "model_RF.fit(X_train_tfidf,y_train)\n",
        "\n",
        "#Prediction on training dataset\n",
        "y_pred = model_RF.predict(X_train_tfidf)\n",
        "print('RMSE on training dataset is : ',mean_squared_error(y_train,y_pred)**0.5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE on training dataset is :  0.2648944171413865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CutiLlUGPXl"
      },
      "source": [
        "#### 7. Hyperparameter tuning\n",
        "\n",
        " - Import GridSearch\n",
        " - Provide the parameter grid to choose:\n",
        "  - max_features â€“ â€˜autoâ€™, â€˜sqrtâ€™, â€˜log2â€™\n",
        "  - max_depth â€“ 10, 15, 20, 25"
      ]
    }
  ]
}